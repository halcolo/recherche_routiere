{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from data_explore_utils import generate_sample_data\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification # To test if RandomForestClassifier is imported correctly\n","from sklearn.metrics import f1_score\n","from data_cleaning_utils import filter_columns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n","import itertools"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('./data/full_data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# Here we prepare our training data\n","We will prepare data separing our Data of the dataframe separing it in groupes of 70% for trainign and 30% for tests \\\n","X -> matrix (n_samples, n_features) \\\n","y -> array (n_samples) with desired output (here i will try with **grav**)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["try: \n","    # We sample our training and testing data\n","    dftrain = df.sample(frac=0.7)\n","    dftest = df.merge(dftrain, how='left', indicator=True)\n","    dftest = dftest[dftest['_merge'] == 'left_only']\n","    dftest = filter_columns(dftest, ['_merge'])\n","\n","    # -- Extracting y from dataframe training and creating array X --\n","    X, y = generate_sample_data(dftrain)\n","\n","    # -- Same for testing data --\n","    Xtest, ytest = generate_sample_data(dftrain)\n","\n","\n","except ValueError as e:\n","    print(e)\n","    exit(1)\n","except Exception as e:\n","    print(e)\n","    exit(1)"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction\n","In the following phase will be evaluated code for the Random forest and the prediction will be scored."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = RandomForestClassifier(\n","    n_estimators=100, \n","    criterion='gini', \n","    n_jobs = -1, \n","    max_depth = None, \n","    min_samples_leaf = 1, \n","    min_samples_split = 10)\n","clf.fit(X, y)\n","\n","y_pred = clf.predict(Xtest)\n","f1 = f1_score(ytest, y_pred, average=\"weighted\")\n","print('Score for this prediction', f1)"]},{"cell_type":"markdown","metadata":{},"source":["# Training the RFC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# Calculer la matrice de confusion\n","conf_matrix = confusion_matrix(ytest, y_pred)\n","\n","# Afficher la matrice de confusion\n","plt.figure(figsize=(8, 6))\n","plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title('Matrice de Confusion')\n","plt.colorbar()\n","\n","# Ajouter les étiquettes aux axes\n","classes = np.unique(y)\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes)\n","plt.yticks(tick_marks, classes)\n","\n","# Ajouter les valeurs dans la matrice\n","thresh = conf_matrix.max() / 2.\n","for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n","    plt.text(j, i, format(conf_matrix[i, j], 'd'),\n","             horizontalalignment=\"center\",\n","             color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n","\n","plt.ylabel('Vraies valeurs')\n","plt.xlabel('Prédictions')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluating features importances"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_importances = clf.feature_importances_\n","col_exclu = 'grav'\n","colonnes_without_grav = [col for col in df.columns if col != col_exclu]\n","plt.figure(figsize=(12, 6))\n","plt.bar(range(len(feature_importances)), feature_importances, tick_label=colonnes_without_grav)\n","plt.xlabel('Feature')\n","plt.ylabel('Feature Importance')\n","plt.title('Feature Importances')\n","plt.xticks(rotation=90, ha=\"right\")  # Rotate x-axis labels for better readability\n","plt.tight_layout()  # Adjust layout to prevent clipping of labels\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Note: Following code take time to execute results."]},{"cell_type":"markdown","metadata":{},"source":["# Searching best hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","PYDEVD_DISABLE_FILE_VALIDATION=1\n","# Définir les hyperparamètres à ajuster\n","param_grid = {\n","    'criterion' : ['gini', 'entropy', 'log_loss'],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10, 20],\n","    'min_samples_leaf': [1, 2, 4, 8, 16],\n","    'n_jobs' : [-1]\n","}\n","# Créer un RandomForestclassifier\n","clf = RandomForestClassifier()\n","# Utiliser GridSearchCV pour trouver les meilleurs hyperparamètres\n","grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs = -1)\n","grid_search.fit(X, y)\n","# Afficher les meilleurs hyperparamètres\n","print(\"Meilleurs hyperparamètres :\", grid_search.best_params_)\n","# Utiliser le modèle avec les meilleurs hyperparamètres\n","best_clf = grid_search.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","y_pred = best_clf.predict(Xtest)\n","f1 = f1_score(ytest, y_pred, average=\"weighted\")\n","print(\"F1 score of best_clf : \" + str(f1))\n","print(classification_report(ytest, y_pred))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
