{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from data_cleaning_utils import clean_csv, filter_columns\n",
    "from utils import set_pandas_display_options\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning dataframes\n",
    "At this section we will clean all DF's using following statements.\n",
    "- Function `clean_csv` used before read csv into DF.\n",
    "    - Clean quotes.\n",
    "    - Clean spaces.\n",
    "    - Delete semicolon and replace each one by colon.\n",
    "\n",
    "- Clean each DF columns (Coluns in Notion, only yes take as necessary col's).\n",
    "- Deleting duplicates from caracteristiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "data_path = current_path + '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up input and output files\n",
    "files = {\n",
    "    \"caracteristiques\":[\"carcteristiques-{year}.csv\", \"carcteristiques-{year}-cleaned.csv\"],\n",
    "    \"lieux\":[\"lieux-{year}.csv\", \"lieux-{year}-cleaned.csv\"],\n",
    "    \"usagers\":[\"usagers-{year}.csv\", \"usagers-{year}-cleaned.csv\"],\n",
    "    \"vehicules\":[\"vehicules-{year}.csv\", \"vehicules-{year}-cleaned.csv\"]\n",
    "}\n",
    "\n",
    "# Run cleaning\n",
    "year = '2022'\n",
    "for g_file in files.values():\n",
    "    input_file = f'{data_path}/2022/{g_file[0].replace(\"{year}\",year)}'  \n",
    "    output_file = f'{data_path}/cleaned/{year}/{g_file[1].replace(\"{year}\", year)}'    \n",
    "    clean_csv(input_file=input_file,\n",
    "              output_file=output_file)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caracteristiques = pd.read_csv(filepath_or_buffer=f'{data_path}/cleaned/{year}/{files[\"caracteristiques\"][1].replace(\"{year}\", year)}')\n",
    "lieux = pd.read_csv(filepath_or_buffer=f'{data_path}/cleaned/{year}/{files[\"lieux\"][1].replace(\"{year}\", year)}')\n",
    "usagers = pd.read_csv(filepath_or_buffer=f'{data_path}/cleaned/{year}/{files[\"usagers\"][1].replace(\"{year}\", year)}')\n",
    "vehicules = pd.read_csv(filepath_or_buffer=f'{data_path}/cleaned/{year}/{files[\"vehicules\"][1].replace(\"{year}\", year)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lieux_col_drop = ['voie', 'v1', 'v2', 'circ', 'nbv', 'pr', 'pr1', 'vosp', 'prof', 'plan', 'lartpc', 'larrout', 'situ']\n",
    "carac_col_drop = ['adr']\n",
    "usag_col_drop = ['secu1', 'secu2', 'secu3']\n",
    "vehic_col_drop = ['senc', 'motor', 'occutc']\n",
    "\n",
    "caracteristiques = filter_columns(caracteristiques, carac_col_drop)\n",
    "lieux = filter_columns(lieux, lieux_col_drop)\n",
    "usagers = filter_columns(usagers, usag_col_drop)\n",
    "vehicules = filter_columns(vehicules, vehic_col_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking and deleting duplicates from caracteristiques\n",
    "caract_dubs = caracteristiques.duplicated(subset=['num_acc'])\n",
    "# last check identify if there are duplicates in the data using boolean values\n",
    "print('joined data total duplicated: %s / %s' % (len(caracteristiques[caract_dubs]), len(caracteristiques)))\n",
    "# drop duplicates\n",
    "caracteristiques = caracteristiques.drop_duplicates(subset=['num_acc'])\n",
    "print('Droped duplicates: %s / %s' % (len(caracteristiques[caract_dubs]), len(caracteristiques)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "- Identified: no unecessary duplicates,\n",
    "- Identified, all data is normalized (no categorical values).\n",
    "- Identified: There's no treshold variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge DF's\n",
    "\n",
    "Each Df will be merged in left join:\n",
    "\n",
    "- merge_1 = Caracteristiques with lieux using `num_acc`.\n",
    "- merge_2 = Usagers with vehicules using `num_acc`, `id_vehicule` and `num_veh`.\n",
    "\n",
    "Each result will be merged to from result merge_1 to merge_2 using `num_acc`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_1 = caracteristiques.merge(lieux, on=\"num_acc\", how='left')\n",
    "merge_2 = usagers.merge(vehicules, on=['num_acc', 'id_vehicule', 'num_veh'], how='left')\n",
    "full_data = merge_2.merge(merge_1, on='num_acc', how='left')\n",
    "# full_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan \n",
    "# Final cleaning\n",
    "\n",
    "# Filled all NaN values with nan\n",
    "full_data = full_data.fillna(nan)\n",
    "\n",
    "# Replacing all an_nais (born year) values by integer values and filling NaN values with 0\n",
    "full_data['an_nais'] = full_data['an_nais'].fillna(0).astype(int)\n",
    "\n",
    "full_data['date'] = pd.to_datetime(full_data['jour'].astype(str) + '-' + full_data['mois'].astype(str) + '-' + full_data['an'].astype(str) + ' ' + full_data['hrmn'].astype(str), format='%d-%m-%Y %H:%M')\n",
    "full_data['timestamp'] = full_data['date'].astype(int) // 10**9\n",
    "data_cols_drop = ['jour', 'mois', 'an', 'hrmn', 'date', 'num_veh', 'num_acc', 'adr', 'voie', 'v1', 'v2', 'occutc', 'lartpc']\n",
    "full_data = filter_columns(full_data, data_cols_drop)\n",
    "\n",
    "# Replacing row specific errors\n",
    "full_data.replace({'A': '10', 'B': '11', \"(1)\" : '1'}, regex=False, inplace=True)\n",
    "full_data.replace({'2A' : '96', '2B' : '97'}, regex=True, inplace = True) #On remplace les corses\n",
    "full_data.drop(full_data[full_data['com'] == \"N/C\"].index, inplace=True)\n",
    "full_data.drop(full_data[full_data['nbv'] == '#ERREUR'].index, inplace=True)\n",
    "\n",
    "# Removing NaN indexes\n",
    "full_data.dropna(inplace=True)\n",
    "\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values dep, com, num_veh, actp are non integer values and is not possible to convert them to integer values\n",
    "# full_data.info()\n",
    "for col in full_data.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data\n",
    "full_data.to_csv(f'{data_path}/full_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
